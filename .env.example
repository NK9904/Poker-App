# Open-Source AI Configuration
VITE_OLLAMA_URL=http://localhost:11434
VITE_OLLAMA_MODEL=llama3.2:3b

# Optional: Custom model configuration
# VITE_OLLAMA_MODEL=codellama:7b
# VITE_OLLAMA_MODEL=llama3.1:8b

# Performance Settings
VITE_MAX_TOKENS=4000
VITE_TEMPERATURE=0.1

# Development Settings
VITE_DEBUG_MODE=false
VITE_ENABLE_ANALYTICS=false